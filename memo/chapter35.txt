FastText 개요
    - 발표: Facebook에서 개발한 Word Embedding 기법.
    - 차별점: Word2Vec, GloVe와 달리 언어의 형태학적 특성을 반영, 희소한 단어에도 Embedding 가능.
    - 기법: 단어를 Bag-of-Characters로 보고 n-gram의 characters를 Embedding (Skip-gram model 사용).
    - 성능: 빠르고 좋은 성능, 내부 단어(Subword) 고려하여 학습.
FastText의 특징
    - OOV (Out Of Vocabulary) 처리: 단어를 글자의 n-gram으로 나타냄, 학습되지 않은 단어도 임베딩 가능.
    - Rare Word 처리: 희소 단어의 경우 문자 n-gram을 이용, Word2Vec 대비 높은 정확도.
FastText와 한국어
    - 글자 단위 임베딩: 예: ‘자연어처리’ → <자연자연어연어처어처리처리>.
    - 자모 단위 임베딩: 초성, 중성, 종성 단위로 분리하여 임베딩.
단어 임베딩 비교
    - Word2Vec: 사용자가 설정한 window 내 등장 단어 벡터 업데이트.
    - GloVe: 단어 동시 등장 여부를 사용 (Term-Context matrix).
    - FastText: 내부 단어(Subword)의 벡터로 표현, 노이즈가 많은 말뭉치에 강점.
임베딩의 한계
    - 의미상 관련 없는 단어 간에도 벡터 공간에 가깝게 임베딩될 수 있음 (예: '소프트웨어', '하드웨어').
    - 모든 임베딩 기법은 동시 등장 정보를 벡터로 표현했을 때 의미를 보존하는 것에 초점을 둠.