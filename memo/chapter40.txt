ELMo (Embeddings from Language Model)
    - 개발: Allen NLP에서 2018년에 개발된 워드 임베딩 기법.
    - 기능: 사전 훈련된 언어 모델을 사용하여 문맥에 따라 단어의 임베딩을 생성.
    - 활용 분야: 기계 번역, 언어 모델링, 텍스트 요약, 개체명 인식, 질문-답변 시스템 등.
ELMo의 특징
    - 문맥 고려: 전통적인 워드 임베딩 방식과 달리, ELMo는 문맥에 따라 각 단어에 대해 다른 벡터를 생성.
    - 성능: 2018년 주요 NLP 작업에서 최고 성능(SOTA)를 달성함.
ELMo의 구조
    - 양방향 언어 모델(biLM): 순방향과 역방향 LSTM을 사용하여 언어 모델을 사전 훈련.
    - 임베딩 방법: Char CNN을 사용하여 글자(character) 단위로 단어를 임베딩합니다. 이로 인해 OOV(Out of Vocabulary) 문제에 견고하며, 한국어 및 일본어에도 적용 가능.
    - 단어 표현 생성: ELMo는 Char CNN 단어 벡터와 중간 단어 벡터의 가중 합으로 최종 단어 벡터를 생성.
ELMo의 적용
    - NLP 작업에의 적용: ELMo 표현은 다양한 NLP 작업에 적용되며, 기존 임베딩과 함께 입력값으로 사용. ELMo는 NLP 작업에 대한 성능을 크게 향상시킬 수 있다.