표현(Representation)
    1. 원 핫-인코딩(One-Hot-Encoding)
        - 원 핫-인코딩은 단어(word)를 숫자로 표현하고자 할 때 적용할 수 있는 간단한 방법론
        - 원핫-인코딩(One-Hot-Encoding)한계점
            - 차원 크기의 문제
                - 단어의 수만큼 차원이 필요함
                - 단어수가 많아졌을때 곤란함
                - 2017년 표준국어대사전에 등재된 단어 수 약 50만개 => 50만개의 차원이 필요
            - 의미를 담지 못하는 문제

    2. 유사도 계산(Similarity)
        1) 유클리디언 거리 (Euclidean Distance)
            정의
            - 두 점 사이의 '직선 거리'를 계산한다.
            - 이는 n차원 공간에서 두 점 (p1, p2, ..., pn)과 (q1, q2, ..., qn) 사이의 거리를 측정하는 가장 일반적인 방법
            한계점
            - 규모 민감성: 특성의 스케일이 다를 경우, 유클리디언 거리는 크게 왜곡될 수 있다.
              ex)한 변수가 다른 변수보다 값의 범위가 훨씬 클 경우, 거리 계산에 더 큰 영향을 미침
            - 차원의 저주: 고차원 데이터에서는 모든 데이터 포인트 간 거리가 비슷해져서 구별하기 어려움
            참고: https://en.wikipedia.org/wiki/Euclidean_distance

        2) 자카드 유사도 (Jaccard Index)
            정의
            - 두 집합 간의 유사도를 측정하는 방법으로, 교집합 크기를 합집합 크기로 나눈 값
            - 적용: 이 방법은 주로 이진 데이터 또는 존재 유무만 중요한 경우에 사용
              ex) 상품 구매 데이터에서 두 고객이 구매한 상품 목록의 유사성을 평가할 때 사용
            참고: https://en.wikipedia.org/wiki/Jaccard_index

        3) 코사인 유사도 (Cosine Similarity)
            정의
            - 두 벡터 간의 각도를 측정하여 유사도를 결정. 코사인 유사도는 두 벡터의 내적을 각 벡터의 크기(유클리드 길이)로 나눈 값
            장점
            - 코사인 유사도는 벡터의 크기에 덜 민감하고, 주로 문서의 유사성을 평가하는 데 사용
              ex) 단어 빈도수를 기반으로 문서 간 유사성을 평가할 때 유용
            참고: https://en.wikipedia.org/wiki/Cosine_similarity

    3. 단어 임베딩 (Word Embedding)
        - 단어 임베딩은 단어의 의미를 간직하는 밀집 벡터(Dense Vector)로 표현하는 방법
        - 벡터가 공간에 꽉 차있음
        - 새로운 단어 추가시 차원을 추가 할 필요가 없음 =>차원을 줄일 수 있음 => 추후 분류나 예측 모델을 학습할 때 연산을 줄일 수 있는 이점을 갖음
        - 단어 임베딩(WordEmbedding)의 한계
            - 벡터로 표현한 단어 차원이 너무 큼 => 밀집 벡터(Dense vector)로 해결
            - 단어 의미를 담지 못함
            - 단어를 벡터로 표현하는 명확한 방법이 존재하지 않음
        - 밀집 벡터를 만드는 방법
            - 분포 가설 : 같은 문맥에서 등장하는 단어는 유사한 의미를 지닌다
                1) 임의의 위치에 벡터 생성
                2) 같은 문맥이 등장하는 단어를 더 가까이 표현

            - 단어 표현(Word Representation)
            - 컴퓨터가 이해할 수 있는 형태로 단어 변환
            - '로컬 표현'과 '분산 표현' 두 종류로 나뉨
                1. 로컬 표현 (Local Representation) - 이산 표현 (Discrete Representation)
                    - 개념: 각 단어를 독립된 식별자나 벡터로 표현. 단어마다 고유 식별자 매핑.
                    - 예시: 원-핫 인코딩. '사과', '바나나', '체리'를 [1, 0, 0], [0, 1, 0], [0, 0, 1]로 표현.
                    - 한계: 단어 간 의미적 관계 표현 못함. 어휘 사전 커지면 벡터 크기도 커짐 (차원의 저주).
                2. 분산 표현 (Distributed Representation) - 연속 표현 (Continuous Representation)
                    - 개념: 단어를 벡터 공간에 표현해 의미적 관계 포착. 벡터 대부분 밀집 형태.
                    - 예시: Word2Vec, GloVe. 주변 단어 정보로 의미적 유사성 포착, 유사 단어들 벡터 공간에서 가까이 위치.
                    - 장점: 단어 간 유사성, 관계 잘 표현. 차원 문제도 일부 해결.
            - 단어 표현 방식에 따라 자연어 처리 성능이 달라진다.
            - 최근 시스템들은 분산 표현을 사용해 효율적, 정교한 언어 모델 구축